{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catch-Up AI Training with a Q-table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define all the function that will be use to simulate a game of Catch-Up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gameOver(state):\n",
    "    '''\n",
    "    gameOver() returns True if there are no more pieces to be chosen.\n",
    "    '''\n",
    "    piecesLeft = (sum(state[:n]))\n",
    "    return not piecesLeft\n",
    "\n",
    "def posAction(state):\n",
    "    '''\n",
    "    posAction(state) will given a state returns a list of all the pieces\n",
    "    that could be chosen.\n",
    "    '''\n",
    "    return [x+1 for x in range(n) if state[x] == 1]\n",
    "\n",
    "def nextState(state, action):\n",
    "    '''\n",
    "    nextState(state, action) transforms one state of the games into\n",
    "    the next one given the taken action.\n",
    "    '''\n",
    "    state = list(state)\n",
    "    state[action - 1] = 0\n",
    "    state[n] += action\n",
    "    if state[n] > state[n+1]:\n",
    "        state = switchPlayer(state)\n",
    "    return tuple(state)\n",
    "\n",
    "def switchPlayer(state):\n",
    "    '''\n",
    "    switchPlayer(state) transforms the state as to make sure that the \n",
    "    player with the lower score is on play.\n",
    "    '''\n",
    "    state = list(state)\n",
    "    state[n], state[n+1] = state[n+1], state[n]\n",
    "    return tuple(state)\n",
    "\n",
    "def determineReward(state):\n",
    "    '''\n",
    "    determineReward(state) returns a reward if the player wins or loses\n",
    "    a game of catch-up.\n",
    "    '''\n",
    "    if gameOver(state) and state[n] > state[n+1]:\n",
    "        return 1\n",
    "    elif gameOver(state) and state[n] < state[n+1]:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def buildStateSpace(state, first = True):\n",
    "    '''\n",
    "    buildStateSpace(state, first = True) will return a generator that\n",
    "    runs over all the possible game states. Take in mind that \n",
    "    duplicates will be included in this iteration.\n",
    "    '''\n",
    "    if first: yield state\n",
    "    posAct = posAction(state)\n",
    "    if len(posAct) > 0:\n",
    "        for action in posAct:\n",
    "            newState = nextState(state, action)\n",
    "            yield newState\n",
    "            for x in buildStateSpace(newState, False):\n",
    "                yield x\n",
    "    else:\n",
    "        yield state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class qTable(object):\n",
    "    '''\n",
    "    qTable() is a class object that contains the Q table and\n",
    "    is able to do operations with this table.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n, learningRate, discountRate):\n",
    "        '''\n",
    "        Initializes the qTable object.\n",
    "        '''\n",
    "        self.lr = learningRate\n",
    "        self.dr = discountRate        \n",
    "        self.table = {}\n",
    "        self.trans = {}\n",
    "        combTable = []\n",
    "            \n",
    "        state = tuple([1 if i < n else 0 for i in range(n+2)])\n",
    "        print(\"Building the Q table...\")\n",
    "        for piece in buildStateSpace(state, True):\n",
    "            self.table[piece] = [0 for _ in range(n)]\n",
    "            # (np.random.random()-0.5)*2\n",
    "            \n",
    "    def update(self, state, newState, action, reward, lr, dr):\n",
    "        '''\n",
    "        update(self, state, newState, action, reward, lr, dr) updates\n",
    "        the Q table given the information gained from the reward, next and\n",
    "        current state. Both learning and discount rate of the model are\n",
    "        required inputs as well.\n",
    "        '''\n",
    "        self.table[state][action-1] = (1 - lr) * self.table[state][action-1] + \\\n",
    "        lr * (reward + dr * max(self.table[newState]))\n",
    "        \n",
    "    def translate(self):\n",
    "        '''\n",
    "        translate() translates the values in the Q table into a table\n",
    "        that gives the suggest move for each state.\n",
    "        '''\n",
    "        for x in self.table.keys():\n",
    "            posAct = posAction(x)\n",
    "            posQ = self.table[x].copy()\n",
    "            action = 0\n",
    "            while len(posAct) > 0:\n",
    "                action = posQ.index(max(posQ)) + 1\n",
    "                if action in posAct:\n",
    "                    break\n",
    "                else:\n",
    "                    posQ[action - 1] = min(posQ) - 1\n",
    "            self.trans[x] = action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def botRandom(state):\n",
    "    '''\n",
    "    Bot chooses any move at random.\n",
    "    '''\n",
    "    posAct = posAction(state)\n",
    "    diff = state[n+1] - state[n]\n",
    "    combAct = []\n",
    "    while (diff > 0 or len(combAct) == 0) and not len(posAct) == 0:\n",
    "        action = np.random.choice(posAct)\n",
    "        combAct.append(action)\n",
    "        posAct.remove(action)\n",
    "        diff = state[n+1] - state[n] - sum(combAct)\n",
    "        \n",
    "    return combAct\n",
    "\n",
    "def botMaxScore(state):\n",
    "    '''\n",
    "    Bot maximizes its scores on every turn, \n",
    "    extending their leads by as much as possible.\n",
    "    '''\n",
    "    posAct = posAction(state)\n",
    "    diff = state[n+1] - state[n]\n",
    "    combAct = []\n",
    "    \n",
    "    # Add the biggest possible pieces that don't trigger\n",
    "    # a change in player.\n",
    "    while not len([x for x in posAct if x < diff]) <= 1 and min(posAct) < diff:\n",
    "        action = max([x for x in posAct if x < diff])\n",
    "        combAct.append(action)\n",
    "        posAct.remove(action)\n",
    "        diff = state[n+1] - state[n] - sum(combAct)\n",
    "    \n",
    "    # Add the biggest possible piece to create the biggest\n",
    "    # extension.\n",
    "    combAct.append(max(posAct))\n",
    "\n",
    "    return combAct\n",
    "\n",
    "def botMinScore(state):\n",
    "    '''\n",
    "    Bot minimizes its scores on every turn\n",
    "    keeping their scores as close as possible.\n",
    "    '''\n",
    "    posAct = posAction(state)\n",
    "    diff = state[n+1] - state[n]\n",
    "    combAct = []\n",
    "    \n",
    "    # Add the biggest possible pieces that don't trigger\n",
    "    # a change in player.\n",
    "    while not len([x for x in posAct if x < diff]) <= 1 and min(posAct) < diff:\n",
    "        action = max([x for x in posAct if x < diff])\n",
    "        combAct.append(action)\n",
    "        posAct.remove(action)\n",
    "        diff = state[n+1] - state[n] - sum(combAct)\n",
    "    \n",
    "    # Add the smallest possible piece to create the smallest\n",
    "    # extensions but not equal.\n",
    "    combAct.append(min(posAct))\n",
    "    \n",
    "    return combAct\n",
    "\n",
    "def botUseMostNums(state):\n",
    "    '''\n",
    "    Bot uses as many numbers as possible, reducing\n",
    "    the numbers available for the opponent.   \n",
    "    '''\n",
    "    posAct = posAction(state)\n",
    "    diff = state[n+1] - state[n]\n",
    "    combAct = []\n",
    "    \n",
    "    while not len([x for x in posAct if x < diff]) <= 1 and min(posAct) < diff:\n",
    "        action = min(posAct)\n",
    "        combAct.append(action)\n",
    "        posAct.remove(action)\n",
    "        diff = state[n+1] - state[n] - sum(combAct)\n",
    "        \n",
    "    # Add the biggest possible piece to create the biggest\n",
    "    # extension.\n",
    "    combAct.append(max(posAct))\n",
    "\n",
    "    return combAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playerAI(state, qTable):\n",
    "    '''\n",
    "    The AI will look into the Q table for the action with\n",
    "    the highest future reward and pick that action. This\n",
    "    function recurses until the AI's turn lapses.\n",
    "    '''\n",
    "    posAct = posAction(state)\n",
    "    diff = state[n+1] - state[n]\n",
    "    \n",
    "    posQ = qTable.table[state].copy()\n",
    "    for _ in range(len(posQ)):\n",
    "        action = posQ.index(max(posQ)) + 1\n",
    "        if action in posAct:\n",
    "            yield action\n",
    "            if diff - action > 0:\n",
    "                newState = nextState(state, action)\n",
    "                yield from playerAI(newState, qTable)\n",
    "            break\n",
    "        else:\n",
    "            posQ[action - 1] = min(posQ) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the AI learn by playing games against the random bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.1\n",
    "discountRate = 0.9\n",
    "n = 10\n",
    "reward = 10\n",
    "\n",
    "# initialize the Q table\n",
    "qTab = qTable(n, learningRate, discountRate)\n",
    "\n",
    "print(\"Training the model...\")\n",
    "for _ in range(1000):\n",
    "    # assemble starting state\n",
    "    state = tuple([1 if i < n else 0 for i in range(n+2)])\n",
    "    # while the game is not finished\n",
    "    while not gameOver(state):\n",
    "        # Player One (Bot)\n",
    "        actions = botRandom(state)\n",
    "\n",
    "        for action in actions:\n",
    "            state = nextState(state, action)\n",
    "        \n",
    "        # Player Two (AI)\n",
    "        if not gameOver(state):\n",
    "            actions = list(playerAI(state, qTab))\n",
    "        \n",
    "            for action in actions:\n",
    "                # find the next state corresponding to the action selected\n",
    "                newState = nextState(state, action)\n",
    "                if state[n] + action > state[n+1]:\n",
    "                    lrFactor = -1\n",
    "                else:\n",
    "                    lrFactor = 1\n",
    "                # get reward factor\n",
    "                rewardFactor = determineReward(newState)\n",
    "                # update Q table\n",
    "                qTab.update(state, newState, action, \n",
    "                                 rewardFactor * reward, \n",
    "                                 learningRate * lrFactor, discountRate)\n",
    "                # got to new state\n",
    "                state = newState      \n",
    "            \n",
    "    if _%50 == 0: print(\"Episode \", _, \" completed.\")\n",
    "print(\"Done training the model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AI has now learned how to play the game and we are now checking how well it does against a random opponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing games...\n",
      "Game  0 finished.\n",
      "Game  1000 finished.\n",
      "Game  2000 finished.\n",
      "Game  3000 finished.\n",
      "Game  4000 finished.\n",
      "Game  5000 finished.\n",
      "Game  6000 finished.\n",
      "Game  7000 finished.\n",
      "Game  8000 finished.\n",
      "Game  9000 finished.\n",
      "10000\n",
      "0.5747\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "\n",
    "print(\"Playing games...\")\n",
    "for _ in range(10000):\n",
    "    # assemble starting state\n",
    "    state = tuple([1 if i < n else 0 for i in range(n+2)])\n",
    "    # while the game is not finished\n",
    "    while not gameOver(state):\n",
    "        # Player One\n",
    "        #actions = botRandom(state)\n",
    "        #actions = botMaxScore(state)\n",
    "        #actions = botMinScore(state)\n",
    "        #actions = botUseMostNums(state)\n",
    "        actions = list(playerAI(state, qTab))\n",
    "        \n",
    "        if len(actions) == len(posAction(state)):\n",
    "            if state[n] + sum(actions) > state[n+1]: score.append(1) # AI loses\n",
    "            elif state[n] + sum(actions) < state[n+1]: score.append(0) # AI wins\n",
    "            else: score.append(0.5) # draw\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        for action in actions:\n",
    "            #print(\"BOT: \", state)\n",
    "            #print(\"-->\", action)\n",
    "            state = nextState(state, action)\n",
    "            #print(\"BOT: \", state)\n",
    "        \n",
    "        # Player Two\n",
    "        if not gameOver(state):\n",
    "            actions = botRandom(state)\n",
    "            #actions = botMaxScore(state)\n",
    "            #actions = botMinScore(state)\n",
    "            #actions = botUseMostNums(state)\n",
    "            #actions = list(playerAI(state, qTab))  \n",
    "            \n",
    "            if len(actions) == len(posAction(state)):\n",
    "                if state[n] + sum(actions) > state[n+1]: score.append(0) # AI wins\n",
    "                elif state[n] + sum(actions) < state[n+1]: score.append(1) # AI loses\n",
    "                else: score.append(0.5) # draw\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            for action in actions:\n",
    "                #print(\"AI: \", state)\n",
    "                #print(\"-->\", action)\n",
    "                state = nextState(state, action)\n",
    "                #print(\"AI: \", state)\n",
    "    \n",
    "    if _%1000==0: print(\"Game \", _, \"finished.\")\n",
    "    #print(score)\n",
    "    #if score[_] == 1: print(\"AI wins!\")\n",
    "    #elif score[_] == 0: print(\"BOT wins!\")\n",
    "    #else: print(\"Draw!\")\n",
    "\n",
    "print(len(score))\n",
    "print(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
