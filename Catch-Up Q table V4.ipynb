{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catch-Up AI Training with a Q-table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define all the function that will be use to simulate a game of Catch-Up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gameOver(state):\n",
    "    '''\n",
    "    gameOver() returns True if there are no more pieces to be chosen.\n",
    "    '''\n",
    "    piecesLeft = (sum(state[:n]))\n",
    "    return not piecesLeft\n",
    "\n",
    "def posAction(state):\n",
    "    '''\n",
    "    posAction(state) will given a state returns a list of all the pieces\n",
    "    that could be chosen.\n",
    "    '''\n",
    "    return [x+1 for x in range(n) if state[x] == 1]\n",
    "\n",
    "def nextState(state, action):\n",
    "    '''\n",
    "    nextState(state, action) transforms one state of the games into\n",
    "    the next one given the taken action.\n",
    "    '''\n",
    "    state = list(state)\n",
    "    state[action - 1] = 0\n",
    "    state[n] += action\n",
    "    if state[n] > state[n+1]:\n",
    "        state = switchPlayer(state)\n",
    "    return tuple(state)\n",
    "\n",
    "def switchPlayer(state):\n",
    "    '''\n",
    "    switchPlayer(state) transforms the state as to make sure that the \n",
    "    player with the lower score is on play.\n",
    "    '''\n",
    "    state = list(state)\n",
    "    state[n], state[n+1] = state[n+1], state[n]\n",
    "    return tuple(state)\n",
    "\n",
    "def determineReward(state):\n",
    "    '''\n",
    "    determineReward(state) returns a reward if the player wins or loses\n",
    "    a game of catch-up.\n",
    "    '''\n",
    "    if gameOver(state) and state[n] > state[n+1]:\n",
    "        return 1\n",
    "    elif gameOver(state) and state[n] < state[n+1]:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def buildStateSpace(state, first = True):\n",
    "    '''\n",
    "    buildStateSpace(state, first = True) will return a generator that\n",
    "    runs over all the possible game states. Take in mind that \n",
    "    duplicates will be included in this iteration.\n",
    "    '''\n",
    "    if first: yield state\n",
    "    posAct = posAction(state)\n",
    "    if len(posAct) > 0:\n",
    "        for action in posAct:\n",
    "            newState = nextState(state, action)\n",
    "            yield newState\n",
    "            for x in buildStateSpace(newState, False):\n",
    "                yield x\n",
    "    else:\n",
    "        yield state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class qTable(object):\n",
    "    '''\n",
    "    qTable() is a class object that contains the Q table and\n",
    "    is able to do operations with this table.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n, learningRate, discountRate):\n",
    "        '''\n",
    "        Initializes the qTable object.\n",
    "        '''\n",
    "        self.lr = learningRate\n",
    "        self.dr = discountRate        \n",
    "        self.table = {}\n",
    "        self.trans = {}\n",
    "        combTable = []\n",
    "            \n",
    "        state = tuple([1 if i < n else 0 for i in range(n+2)])\n",
    "        for piece in buildStateSpace(state, True):\n",
    "            self.table[piece] = [0 for _ in range(n)]\n",
    "            # (np.random.random()-0.5)*2\n",
    "            \n",
    "    def update(self, state, newState, action, reward, lr, dr):\n",
    "        '''\n",
    "        update(self, state, newState, action, reward, lr, dr) updates\n",
    "        the Q table given the information gained from the reward, next and\n",
    "        current state. Both learning and discount rate of the model are\n",
    "        required inputs as well.\n",
    "        '''\n",
    "        self.table[state][action-1] = (1 - lr) * self.table[state][action-1] + \\\n",
    "        lr * (reward + dr * max(self.table[newState]))\n",
    "        \n",
    "    def translate(self):\n",
    "        '''\n",
    "        translate() translates the values in the Q table into a table\n",
    "        that gives the suggest move for each state.\n",
    "        '''\n",
    "        for x in self.table.keys():\n",
    "            posAct = posAction(x)\n",
    "            posQ = self.table[x].copy()\n",
    "            action = 0\n",
    "            while len(posAct) > 0:\n",
    "                action = posQ.index(max(posQ)) + 1\n",
    "                if action in posAct:\n",
    "                    break\n",
    "                else:\n",
    "                    posQ[action - 1] = min(posQ) - 1\n",
    "            self.trans[x] = action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def botRandom(state):\n",
    "    '''\n",
    "    Bot chooses any move at random.\n",
    "    '''\n",
    "    posAct = posAction(state)\n",
    "    diff = state[n+1] - state[n]\n",
    "    combAct = []\n",
    "    while (diff > 0 or len(combAct) == 0) and not len(posAct) == 0:\n",
    "        action = np.random.choice(posAct)\n",
    "        combAct.append(action)\n",
    "        posAct.remove(action)\n",
    "        diff = state[n+1] - state[n] - sum(combAct)\n",
    "        \n",
    "    return combAct\n",
    "\n",
    "def botMaxScore(state):\n",
    "    '''\n",
    "    Bot maximizes its scores on every turn, \n",
    "    extending their leads by as much as possible.\n",
    "    '''\n",
    "    posAct = posAction(state)\n",
    "    diff = state[n+1] - state[n]\n",
    "    combAct = []\n",
    "    \n",
    "    # Add the biggest possible pieces that don't trigger\n",
    "    # a change in player.\n",
    "    while (min(posAct) < diff or len(combAct) == 0) and not len(posAct) == 0:\n",
    "        action = max([x for x in posAct if x < diff])\n",
    "        combAct.append(action)\n",
    "        posAct.remove(action)\n",
    "        diff = state[n+1] - state[n] - sum(combAct)\n",
    "    \n",
    "    # Add the biggest possible piece to create the biggest\n",
    "    # extension.\n",
    "    combAct.append(max(posAct))\n",
    "\n",
    "    return combAct\n",
    "\n",
    "def botMinScore(state):\n",
    "    '''\n",
    "    Bot minimizes its scores on every turn\n",
    "    keeping their scores as close as possible.\n",
    "    '''\n",
    "    posAct = posAction(state)\n",
    "    diff = state[n+1] - state[n]\n",
    "    combAct = []\n",
    "    \n",
    "    # Add the biggest possible pieces that don't trigger\n",
    "    # a change in player.\n",
    "    while (min(posAct) < diff or len(combAct) == 0) and not len(posAct) == 0:\n",
    "        action = max([x for x in posAct if x < diff])\n",
    "        combAct.append(action)\n",
    "        posAct.remove(action)\n",
    "        diff = state[n+1] - state[n] - sum(combAct)\n",
    "    \n",
    "    # Add the smallest possible piece to create the smallest\n",
    "    # extensions but not equal.\n",
    "    combAct.append(min(posAct))\n",
    "    \n",
    "    return combAct\n",
    "\n",
    "def botUseMostNums(state):\n",
    "    '''\n",
    "    Bot uses as many numbers as possible, reducing\n",
    "    the numbers available for the opponent.   \n",
    "    '''\n",
    "    posAct = posAction(state)\n",
    "    diff = state[n+1] - state[n]\n",
    "    combAct = []\n",
    "    \n",
    "    while (min(posAct) < diff or len(combAct) == 0) and not len(posAct) == 0:\n",
    "        action = min(posAct)\n",
    "        combAct.append(action)\n",
    "        posAct.remove(action)\n",
    "        diff = state[n+1] - state[n] - sum(combAct)\n",
    "        \n",
    "    # Add the biggest possible piece to create the biggest\n",
    "    # extension.\n",
    "    combAct.append(max(posAct))\n",
    "\n",
    "    return combAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playerAI(state, qTable):\n",
    "    '''\n",
    "    The AI will look into the Q table for the action with\n",
    "    the highest future reward and pick that action. This\n",
    "    function recurses until the AI's turn lapses.\n",
    "    '''\n",
    "    posAct = posAction(state)\n",
    "    diff = state[n+1] - state[n]\n",
    "    \n",
    "    posQ = qTable.table[state].copy()\n",
    "    for _ in range(len(posQ)):\n",
    "        action = posQ.index(max(posQ)) + 1\n",
    "        if action in posAct:\n",
    "            yield action\n",
    "            if diff - action > 0:\n",
    "                newState = nextState(state, action)\n",
    "                yield from playerAI(newState, qTable)\n",
    "            break\n",
    "        else:\n",
    "            posQ[action - 1] = min(posQ) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 1, 1, 1, 0, 0): 1,\n",
       " (0, 1, 1, 1, 0, 1): 2,\n",
       " (0, 0, 1, 1, 1, 2): 4,\n",
       " (0, 0, 0, 1, 2, 4): 4,\n",
       " (0, 0, 0, 0, 4, 6): 0,\n",
       " (0, 0, 1, 0, 2, 5): 3,\n",
       " (0, 0, 0, 0, 5, 5): 0,\n",
       " (0, 1, 0, 1, 1, 3): 2,\n",
       " (0, 0, 0, 1, 3, 3): 4,\n",
       " (0, 0, 0, 0, 3, 7): 0,\n",
       " (0, 1, 0, 0, 3, 5): 2,\n",
       " (0, 1, 1, 0, 1, 4): 2,\n",
       " (0, 0, 1, 0, 3, 4): 3,\n",
       " (0, 1, 0, 0, 4, 4): 2,\n",
       " (1, 0, 1, 1, 0, 2): 1,\n",
       " (1, 0, 0, 1, 2, 3): 1,\n",
       " (1, 0, 0, 0, 3, 6): 1,\n",
       " (1, 0, 1, 0, 2, 4): 1,\n",
       " (1, 0, 0, 0, 4, 5): 1,\n",
       " (1, 1, 0, 1, 0, 3): 1,\n",
       " (1, 1, 0, 0, 3, 4): 1,\n",
       " (1, 1, 1, 0, 0, 4): 1}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learningRate = 0.1\n",
    "discountRate = 0.9\n",
    "n = 4\n",
    "reward = 10\n",
    "\n",
    "# initialize the Q table\n",
    "qTab = qTable(n, learningRate, discountRate)\n",
    "\n",
    "for _ in range(1000):\n",
    "    # assemble starting state\n",
    "    state = tuple([1 if i < n else 0 for i in range(n+2)])\n",
    "    # while the game is not finished\n",
    "    while not gameOver(state):\n",
    "        # Player One (Bot)\n",
    "        actions = botRandom(state)\n",
    "\n",
    "        for action in actions:\n",
    "            state = nextState(state, action)\n",
    "        \n",
    "        if not gameOver(state):\n",
    "        # Player Two (AI)\n",
    "            actions = list(playerAI(state, qTab))\n",
    "        \n",
    "            for action in actions:\n",
    "                # find the next state corresponding to the action selected\n",
    "                newState = nextState(state, action)\n",
    "                if state[n] + action > state[n+1]:\n",
    "                    lrFactor = -1\n",
    "                else:\n",
    "                    lrFactor = 1\n",
    "                # get reward factor\n",
    "                rewardFactor = determineReward(newState)\n",
    "                # update Q table\n",
    "                qTab.update(state, newState, action, \n",
    "                                 rewardFactor * reward, \n",
    "                                 learningRate * lrFactor, discountRate)\n",
    "                # got to new state\n",
    "                state = newState      \n",
    "            \n",
    "    #print(\"Episode \", _, \" completed.\")\n",
    "    \n",
    "qTab.translate()\n",
    "qTab.trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
